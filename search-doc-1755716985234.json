[{"title":"General Framework","type":0,"sectionRef":"#","url":"/docs/docs/general_framework/","content":"","keywords":"framework","version":"Next"},{"title":"References​","type":1,"pageTitle":"General Framework","url":"/docs/docs/general_framework/#references","content":"[1] Salganik, Matthew J. 2017. Bit by Bit: Social Research in the Digital Age. Princeton, NJ: Princeton University Press. Open review edition. ","version":"Next","tagName":"h2"},{"title":"Bringing \"balance\" to your data","type":0,"sectionRef":"#","url":"/blog/2023/01/09/bringing-balance-to-your-data/","content":"","keywords":"","version":null},{"title":"balance: a Python package for adjusting biased samples​","type":1,"pageTitle":"Bringing \"balance\" to your data","url":"/blog/2023/01/09/bringing-balance-to-your-data/#balance-a-python-package-for-adjusting-biased-samples","content":"With survey data playing a key role in research and product work at Meta, we observed a growing need for software tools that make survey statistics methods accessible for researchers and engineers. This has led us to develop “balance”: A Python package for adjusting biased data samples. In balance we introduce a simple easy-to-use framework for weighting data and evaluating its biases with and without adjustments. The package is designed to provide best practices for weights fitting and offers several modeling approaches. The methodology in “balance” already supports ongoing automated survey data processing at Meta, as well as ad-hoc analyses of survey data by dozens of researchers every month. The main workflow API of balance includes three steps: (1) understanding the initial bias in the data relative to a target we would like to infer, (2) adjusting the data to correct for the bias by producing weights for each unit in the sample based on propensity scores, and (3) evaluating the final bias and the variance inflation after applying the fitted weights. The adjustment step provides several alternatives for the researcher to choose from. Current options include: Inverse propensity weighting of the form of logistic regression model based on LASSO (Least Absolute Shrinkage and Selection Operator [1]), Covariate Balancing Propensity Scores [2], and post-stratification. The focus is on providing a simple to use API, based on Pandas DataFrame structure, that can be used by researchers from a wide spectrum of fields. We’re releasing “balance” as a Meta Open Source project. We want researchers, data scientists, engineers, and other practitioners to be able to apply these practices when they work in Python, benefiting from Meta’s long research and experience in the field. With relation to “balance” we hope to also create an active community of data science practitioners where people can come together to discuss methodology and build tools that benefit survey-based research across academia and industry. If you work in Python with potentially biased data, we encourage you to use “balance” in your project. “balance“ website: https://import-balance.org/ github repository: https://github.com/facebookresearch/balance References [1] Tibshirani, R. (1996). Regression shrinkage and selection via the lasso. Journal of the Royal Statistical Society: Series B (Methodological), 58(1), 267-288. [2] Imai, K., &amp; Ratkovic, M. (2014). Covariate balancing propensity score. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 76(1), 243-263. ","version":null,"tagName":"h2"},{"title":"Contributing","type":0,"sectionRef":"#","url":"/docs/docs/contributing/","content":"","keywords":"","version":"Next"},{"title":"Pull Requests​","type":1,"pageTitle":"Contributing","url":"/docs/docs/contributing/#pull-requests","content":"We actively welcome your pull requests. Fork the repo and create your branch from main.If you've added code that should be tested, add tests.If you've changed APIs, update the documentation.Ensure the test suite passes.Make sure your code lints.If you haven't already, complete the Contributor License Agreement (&quot;CLA&quot;). ","version":"Next","tagName":"h2"},{"title":"Contributor License Agreement (\"CLA\")​","type":1,"pageTitle":"Contributing","url":"/docs/docs/contributing/#contributor-license-agreement-cla","content":"In order to accept your pull request, we need you to submit a CLA. You only need to do this once to work on any of Meta's open source projects. Complete your CLA here: https://code.facebook.com/cla ","version":"Next","tagName":"h2"},{"title":"Issues​","type":1,"pageTitle":"Contributing","url":"/docs/docs/contributing/#issues","content":"We use GitHub issues to track public bugs. Please ensure your description is clear and has sufficient instructions to be able to reproduce the issue. Meta has a bounty program for the safe disclosure of security bugs. In those cases, please go through the process outlined on that page and do not file a public issue. ","version":"Next","tagName":"h2"},{"title":"Code Requirements​","type":1,"pageTitle":"Contributing","url":"/docs/docs/contributing/#code-requirements","content":"","version":"Next","tagName":"h2"},{"title":"Coding Style​","type":1,"pageTitle":"Contributing","url":"/docs/docs/contributing/#coding-style","content":"4 spaces for indentation rather than tabs80 character line length ","version":"Next","tagName":"h3"},{"title":"Linting​","type":1,"pageTitle":"Contributing","url":"/docs/docs/contributing/#linting","content":"Run the linter via flake8 (pip install flake8) from the root of the Ax repository. Note that we have a custom flake8 configuration. ","version":"Next","tagName":"h3"},{"title":"Static Type Checking​","type":1,"pageTitle":"Contributing","url":"/docs/docs/contributing/#static-type-checking","content":"We use Pyre for static type checking and require code to be fully type annotated. ","version":"Next","tagName":"h3"},{"title":"Unit testing​","type":1,"pageTitle":"Contributing","url":"/docs/docs/contributing/#unit-testing","content":"We strongly recommend adding unit testing when introducing new code. To run all unit tests, we recommend installing pytest using pip install pytest and running pytest -ra from the root of the balance repo. ","version":"Next","tagName":"h3"},{"title":"Documentation​","type":1,"pageTitle":"Contributing","url":"/docs/docs/contributing/#documentation","content":"We require docstrings on all public functions and classes (those not prepended with _).We use the Google docstring style &amp; use Sphinx to compile API reference documentation.Our website leverages Docusaurus 2.0 + Sphinx + Jupyter notebook for generating our documentation content.To rule out parsing errors, we suggesting installing sphinx and running make html from the balance/sphinx folder. ","version":"Next","tagName":"h3"},{"title":"Website Development​","type":1,"pageTitle":"Contributing","url":"/docs/docs/contributing/#website-development","content":"","version":"Next","tagName":"h2"},{"title":"Overview​","type":1,"pageTitle":"Contributing","url":"/docs/docs/contributing/#overview","content":"balance's website is also open source and part of this repository. balance leverages several open source frameworks for website development. Docusaurus 2: The main site is generated using Docusaurus, with the code living under the website folder). This includes the website template (navbar, footer, sidebars), landing page, and main sections (Blog, Docs, Tutorials, API Reference). Markdown is used for the content of several sections, particularly the &quot;Docs&quot; section. Files are under the docs/ folder Jupyter notebook is used to generate the notebook tutorials under the &quot;Tutorials&quot; section, based on our ipynb tutorials in our tutorials folder.Sphinx is used for Python documentation generation, populated under the &quot;API Reference&quot; section. Files are under the sphinx folder. ","version":"Next","tagName":"h3"},{"title":"Setup​","type":1,"pageTitle":"Contributing","url":"/docs/docs/contributing/#setup","content":"To install the necessary dependencies for website development, run the following from the repo root: python -m pip install git+https://github.com/bbalasub1/glmnet_python.git@1.0 python -m pip install .[dev]  ","version":"Next","tagName":"h3"},{"title":"Adding Notebook Tutorials​","type":1,"pageTitle":"Contributing","url":"/docs/docs/contributing/#adding-notebook-tutorials","content":"All our notebook tutorials are housed under the tutorials folder at the root of the repo. We use these notebooks as the source of truth for the &quot;Tutorials&quot; section of the website, executing &amp; generating HTML pages for each notebook. To add a new tutorial: Check in your notebook (.ipynb) to our tutorials folder. We strongly suggest clearing notebook output cells.Extend the &quot;Building tutorial HTML&quot; section of scripts/make_docs.sh to execute &amp; generate HTML for the new tutorial e.g. jupyter nbconvert tutorials/my_tutorial.ipynb --execute --to html --output-dir website/static/html/tutorials.Introduce a new .mdx page under the website/docs/tutorials folder for the new tutorial. Use HTMLLoader to load the generated HTML e.g. &lt;HTMLLoader docFile={useBaseUrl('html/tutorials/my_tutorial.html')}/&gt;. quickstart.mdx is a good reference for the setup To test the setup, see the Building &amp; Testing Website Changes section below. Note: The generated HTML should not be checked into the main repo. ","version":"Next","tagName":"h3"},{"title":"Building & Testing Website Changes​","type":1,"pageTitle":"Contributing","url":"/docs/docs/contributing/#building--testing-website-changes","content":"We've developed a helper script for running the full website build process: ./scripts/make_docs.sh # To start up the local webserver cd website yarn serve  Once the local webserver is up, you'll get a link you can follow to visit the newly-built site. See Docusaurus docs for more info. ","version":"Next","tagName":"h3"},{"title":"Deployment​","type":1,"pageTitle":"Contributing","url":"/docs/docs/contributing/#deployment","content":"We rely on Github Actions to run our CI/CD. The workflow files can be found here. In summary On every pull request, we run our &quot;Build &amp; Test&quot; workflow, which includes PyTest tests, Wheels package builds, flake8 linting, and website build.We also run the same &quot;Build &amp; Test&quot; suite nightly.On every push, we deploy a new version of the website. The make_docs.sh script is run from the main branch and the build artifacts are published to the gh-pages branch, which is linked to our repo's Github Page's deployment. ","version":"Next","tagName":"h2"},{"title":"Releasing a new version​","type":1,"pageTitle":"Contributing","url":"/docs/docs/contributing/#releasing-a-new-version","content":"To create a new release, simply navigate to the &quot;Release&quot; page of the repo, draft a new release, and publish. The Github Action workflow should be triggered on publish and you should see a new version of the package live on PyPi in ~10 mins. You can check the status of the job via the GH Actions tab. Guidelines when drafting a new release: Follow semantic versioning conventions when chosing the next version.The release's tag should only be the version itself (e.g. &quot;0.1.0&quot;). Do not add any prefixes like &quot;v&quot; or &quot;version&quot;. The build process relies on proper formatting of this tag. The Github Actions job is configured at release.yml. ","version":"Next","tagName":"h3"},{"title":"License​","type":1,"pageTitle":"Contributing","url":"/docs/docs/contributing/#license","content":"By contributing to balance, you agree that your contributions will be licensed under the LICENSE file in the root directory of this source tree. ","version":"Next","tagName":"h2"},{"title":"Adjusting Sample to Population","type":0,"sectionRef":"#","url":"/docs/docs/general_framework/adjusting_sample_to_population/","content":"","keywords":"adjustment","version":"Next"},{"title":"Optional arguments​","type":1,"pageTitle":"Adjusting Sample to Population","url":"/docs/docs/general_framework/adjusting_sample_to_population/#optional-arguments","content":"method: ipw, poststratify, rake, or cbps. Default is ipw. ipw: stands for Inverse Propensity Weighting. The propensity scores are calculated with LASSO logistic regression. Details about the implementation can be found here. For a quick-start tutorial, see here.cbps: stands for Covariate Balancing Propensity Score. The CBPS algorithm estimates the propensity score in a way that optimizes prediction of the probability of sample inclusion as well as the covariates balance. Its main advantage is in cases when the researcher wants better balance on the covariates than traditional propensity score methods - because one believes the assignment model might be misspecified and would like to avoid an iterative procedure of balancing the covariates. Details about the implementation can be found here. For a quick-start tutorial, see here.poststratify: stands for post-stratification. Details about the implementation can be found here.rake: Details about the implementation can be found here. For a quick-start tutorial, see here. variables: allows user to pass a list of the covariates that they want to adjust for; if variables argument is not specified, all joint variables in sample and target are used. transformations: which transformations to apply to data before fitting the model. Default is cutting numeric variables into 10 quantile buckets and lumping together infrequent levels with less than 5% prevalence into lumped_other category. The transformations are done on both the sample dataframe and the target dataframe together. User can also specify specific transformations in a dictionary format. For a quick-start tutorial on transformations and formulas, see here. max_de: (for ipw and cbps methods): The default value is 1.5. It limits the design effect to be within 1.5. If set to None, the optimization is performed by cross-validation of the logistic model for ipw (see the choose_regularization function for more details) or without constrained optimization for cbps. Setting max_de to None can sometimes significantly improve the running time of the code. weight_trimming_mean_ratio or weight_trimming_percentile: (only one of these arguments can be specified). weight_trimming_mean_ratio indicates the ratio from above according to which the weights are trimmed by mean(weights) * ratio. Default is 20. If weight_trimming_percentile is not none, winsorization is applied. Default is None, i.e. trimming from above is applied. However, note that when max_de is not None (and default is 1.5), the trimming-ratio is optimized by ipw and these arguments are ignored. na_action (for ipw method): how to handle missing values in the data (sample and target). Default is to replace NAs with 0's and add indicator for which observations were NA (this is done after applying the transformations). Another option is drop, which drops all observations with NA values. formula (for ipw and cbps methods): The formula according to which build the model matrix for the logistic regression. Default is a linear additive formula of all covariates. For a quick-start tutorial on transformations and formulas, see here. penalty_factor (for ipw method): the penalty used in the regularized logistic regression. ","version":"Next","tagName":"h2"},{"title":"Evaluating and using the adjustment weights","type":0,"sectionRef":"#","url":"/docs/docs/general_framework/evaluation_of_results/","content":"","keywords":"diagnostics evaluation results","version":"Next"},{"title":"Summary statistics​","type":1,"pageTitle":"Evaluating and using the adjustment weights","url":"/docs/docs/general_framework/evaluation_of_results/#summary-statistics","content":"","version":"Next","tagName":"h2"},{"title":"Summary​","type":1,"pageTitle":"Evaluating and using the adjustment weights","url":"/docs/docs/general_framework/evaluation_of_results/#summary","content":"Printing the adjusted object gives a high level overview of the content of the object: print(adjusted)  Output: Adjusted balance Sample object with target set using ipw 1000 observations x 3 variables: gender,age_group,income id_column: id, weight_column: weight, outcome_columns: happiness target: balance Sample object 10000 observations x 3 variables: gender,age_group,income id_column: id, weight_column: weight, outcome_columns: None 3 common variables: income,age_group,gender  To generate a summary of the data, use the summary method: print(adjusted.summary())  This will return several results: Covariate mean ASMD improvement: ASMD is &quot;Absolute Standardized Mean Difference&quot;. For continuous variables, this measure is the same as taking the absolute value of Cohen's d statistic (also related to SSMD), when using the (weighted) standard deviation of the target population. For categorical variables it uses one-hot encoding.Design effectCovariate mean Adjusted Standardized Mean Deviation (ASMD) versus Unadjusted covariate mean ASMDModel proportion deviance explained (if inverese propensity weighting method was used) Output: Covar ASMD reduction: 62.3%, design effect: 2.249 Covar ASMD (7 variables): 0.335 -&gt; 0.126 Model performance: Model proportion deviance explained: 0.174  Note that although we had 3 variables in our original data (age_group, gender, income), the asmd counts each level of the categorical variables as separate variable, and thus it considered 7 variables for the covar ASMD improvement. ","version":"Next","tagName":"h3"},{"title":"Covariate Balance​","type":1,"pageTitle":"Evaluating and using the adjustment weights","url":"/docs/docs/general_framework/evaluation_of_results/#covariate-balance","content":"We can check the mean of each variable before and after applying the weights using .mean(): adjusted.covars().mean().T  To get: source self target unadjusted _is_na_gender[T.True] 0.103449 0.089800 0.08800 age_group[T.25-34] 0.279072 0.297400 0.30900 age_group[T.35-44] 0.290137 0.299200 0.17200 age_group[T.45+] 0.150714 0.206300 0.04600 gender[Female] 0.410664 0.455100 0.26800 gender[Male] 0.485887 0.455100 0.64400 gender[_NA] 0.103449 0.089800 0.08800 income 9.519935 12.737608 5.99102  The self is the adjusted ASMD, while unadjusted is the unadjusted ASMD. And .asmd() to get ASMD: adjusted.covars().asmd().T  To get: source self unadjusted unadjusted - self age_group[T.25-34] 0.040094 0.025375 -0.014719 age_group[T.35-44] 0.019792 0.277771 0.257980 age_group[T.45+] 0.137361 0.396127 0.258765 gender[Female] 0.089228 0.375699 0.286472 gender[Male] 0.061820 0.379314 0.317494 gender[_NA] 0.047739 0.006296 -0.041444 income 0.246918 0.517721 0.270802 mean(asmd) 0.126310 0.334860 0.208551  We can see that on average the ASMD improved from 0.33 to 0.12 thanks to the weights. We got improvements in income, gender, and age_group. Although we can see that age_group[T.25-34] didn't get improved. ","version":"Next","tagName":"h2"},{"title":"Understanding the model​","type":1,"pageTitle":"Evaluating and using the adjustment weights","url":"/docs/docs/general_framework/evaluation_of_results/#understanding-the-model","content":"For a summary of the diagnostics measures, use: adjusted.diagnostics()  This will give a long table that can be filterred to focus on various diagnostics metrics. For example, when the .adjust() method is run with model=&quot;ipw&quot; (the default method), then the rows from the diagnostics output with metric == &quot;model_coef&quot; represent the coefficients of the variables in the model. These can be used to understand the model that was fitted (after transformations and regularization). ","version":"Next","tagName":"h2"},{"title":"Visualization post adjustments​","type":1,"pageTitle":"Evaluating and using the adjustment weights","url":"/docs/docs/general_framework/evaluation_of_results/#visualization-post-adjustments","content":"We can create all (interactive) plots using: adjusted.covars().plot()  And get:    We can also use different plots, using the seaborn library, for example with the &quot;kde&quot; dist_type. adjusted.covars().plot(library = &quot;seaborn&quot;, dist_type = &quot;kde&quot;)  And get:  ","version":"Next","tagName":"h2"},{"title":"Distribution of Weights​","type":1,"pageTitle":"Evaluating and using the adjustment weights","url":"/docs/docs/general_framework/evaluation_of_results/#distribution-of-weights","content":"We can look at the distribution of weights using the following method call: adjusted.weights().plot()  And get:  Or calculate the design effect using: adjusted.weights().design_effect() # 2.24937  ","version":"Next","tagName":"h2"},{"title":"Analyzing the outcome​","type":1,"pageTitle":"Evaluating and using the adjustment weights","url":"/docs/docs/general_framework/evaluation_of_results/#analyzing-the-outcome","content":"The .summary() method gives us the response rates (if we have missing values in the outcome), and the weighted means before and after applying the weights: print(adjust.outcomes().summary())  To get:  1 outcomes: ['happiness'] Mean outcomes: happiness source self 54.221388 unadjusted 48.392784 Response rates (relative to number of respondents in sample): happiness n 1000.0 % 100.0  For example, we see that the estimated mean happiness according to our sample is 48 without any adjustment and 54 with adjustment. The following shows the distribution of happinnes before and after applying the weights: adjusted.outcomes().plot()  And we get:  ","version":"Next","tagName":"h2"},{"title":"Pre-Adjustment Diagnostics","type":0,"sectionRef":"#","url":"/docs/docs/general_framework/pre_adjustment_diagnostics/","content":"","keywords":"unadjusted sample diagnostics","version":"Next"},{"title":"Covariate balance​","type":1,"pageTitle":"Pre-Adjustment Diagnostics","url":"/docs/docs/general_framework/pre_adjustment_diagnostics/#covariate-balance","content":"A way to check if adjustments are needed is looking at covariate balance by comparing the distribution of covariates in our sample (the respondents before any adjustment), to the distribution of covariates of the population. The same methods will be later used to evaluate the quality of the adjustment in evaluating the results. There are various methods for comparing covariate balance, either via summary statistics, or through visualizations. The visualizations are implemented either via plotly (offering an interactive interface) or seaborn (leading to a static image). The methods implemented in balance include: Summary statistics MeansASMD (Absolute Standardized Mean Difference) Visualizations Numerical variables QQ-plots (interactive)Kernel density estimation (static)Empirical Cumulative Distribution Function (static)Histogram (static) Categorical variables Barplots (interactive or static)Probability scatter plot (static) ","version":"Next","tagName":"h2"},{"title":"Summary statistics​","type":1,"pageTitle":"Pre-Adjustment Diagnostics","url":"/docs/docs/general_framework/pre_adjustment_diagnostics/#summary-statistics","content":"","version":"Next","tagName":"h2"},{"title":"Means and ASMD (Absolute Standardized Mean Difference)​","type":1,"pageTitle":"Pre-Adjustment Diagnostics","url":"/docs/docs/general_framework/pre_adjustment_diagnostics/#means-and-asmd-absolute-standardized-mean-difference","content":"The mean of the covariates in the sample versus the target is a basic measure to evaluate the distance of the sample from the target population of interest. For categorical variables the means are calculated to each of the one-hot encoding of the categories of the variable. This is basically the proportion of observations in that bucket. It can be calculated simply by running: sample_with_target.covars().mean().T  An example of the output: source self target _is_na_gender[T.True] 0.08800 0.089800 age_group[T.25-34] 0.30900 0.297400 age_group[T.35-44] 0.17200 0.299200 age_group[T.45+] 0.04600 0.206300 gender[Female] 0.26800 0.455100 gender[Male] 0.64400 0.455100 gender[_NA] 0.08800 0.089800 income 5.99102 12.737608  (TODO: the one hot encoding acts a bit differently for different variables - this will be resolved in future releases) The limitation of the mean is that it is not easily comparable between different variables since they may have different variances. The simplest attempt in addressing this issue is using the ASMD. The ASMD (Absolute Standardized Mean Deviation) measures the difference per covariate between the sample and target. It uses weighted average and std for the calculations (e.g.: to take design weights into account). This measure is the same as taking the absolute value of Cohen's d statistic (also related to SSMD), when using the (weighted) standard deviation of the target population. Other options that occur in the literature includes using the standard deviation based on the sample, or some average of the std of the sample and the target. In order to allow this to be compared across different samples and adjustments, we opted to use the std of the target as the default. It can be calculated simply by running: sample_with_target.covars().asmd().T  An example of the output: source self age_group[T.25-34] 0.025375 age_group[T.35-44] 0.277771 age_group[T.45+] 0.396127 gender[Female] 0.375699 gender[Male] 0.379314 gender[_NA] 0.006296 income 0.517721 mean(asmd) 0.334860  For categorical variables the ASMD can be calculated as the average of the ASMD applied to each of the one-hot encoding of the categories of the variable by using the aggregate_by_main_covar argument: sample_with_target.covars().asmd(aggregate_by_main_covar = True).T  The output: source self age_group 0.233091 gender 0.253769 income 0.517721 mean(asmd) 0.334860  An average ASMD is calculated for all covariates. It is a simple average of the ASMD for each covariate. Each ASMD value of categorical variable is used once after aggregated the ASMD from all the dummy variables. ","version":"Next","tagName":"h3"},{"title":"Visualizations​","type":1,"pageTitle":"Pre-Adjustment Diagnostics","url":"/docs/docs/general_framework/pre_adjustment_diagnostics/#visualizations","content":"","version":"Next","tagName":"h2"},{"title":"Q-Q Plot (plotly)​","type":1,"pageTitle":"Pre-Adjustment Diagnostics","url":"/docs/docs/general_framework/pre_adjustment_diagnostics/#q-q-plot-plotly","content":"We provide Q-Q Plots as a visual to compare two distributions to one another. For example, the plot below is a Q-Q plot for the income covariate for the sample against a straight line of the target population:  The closer the line is to the 45-degree-line the better (i.e.: the less bias is observed in the sample as compared to the target population). To make a QQ-plot for a specific variable, simply use the following method (the default uses QQ plot with the plotly engine): sample_with_target.covars().plot(variables = ['income',])  ","version":"Next","tagName":"h3"},{"title":"Barplots​","type":1,"pageTitle":"Pre-Adjustment Diagnostics","url":"/docs/docs/general_framework/pre_adjustment_diagnostics/#barplots","content":"Barplots provides a way to visually compare the sample and target for categorical covariates. Here is an example of the plot for age_group and gender before adjustment:   To make these plots, simply use the following: sample_with_target.covars().plot(variables = ['age_group', 'gender', ])  ","version":"Next","tagName":"h3"},{"title":"Plotting all varibales​","type":1,"pageTitle":"Pre-Adjustment Diagnostics","url":"/docs/docs/general_framework/pre_adjustment_diagnostics/#plotting-all-varibales","content":"If you do not specify a variables list in the plot method, all covariates of you sample object will be plotted: sample_with_target.covars().plot()  ","version":"Next","tagName":"h3"},{"title":"Statistical Methods","type":0,"sectionRef":"#","url":"/docs/docs/statistical_methods/","content":"Statistical Methods This section descirbes the statistical methodologies used in balance for weighting: Inverse propensity score weightingCovariate balancing proponsity scorePost-stratificationRaking","keywords":"","version":"Next"},{"title":"Post-Stratification","type":0,"sectionRef":"#","url":"/docs/docs/statistical_methods/poststratify/","content":"","keywords":"Post-Stratification poststratify","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Post-Stratification","url":"/docs/docs/statistical_methods/poststratify/#introduction","content":"Post-stratification is one of the most common weighing approaches in survey statistics. It origins from a stratified sample, where the population is divided into subpopulations (strata) and the sample is conducted independently on each of them. However, when one doesn't know in advance the subpopulations to sample from (for example, when the stratum of the units in the sample is unknown in advance), or when non-response is presented, stratification can be done after the sample has been selected. The goal of post-stratification is to have the sample match exactly the joint-distribution of the target population. However, this is also the main limitation of this method. It is limited by the number of variables we are able to use for adjustment due to the nature of fitting the target exactly, and thus require a minimal number of respondent in each strata. Hence, usually at most 2 to 4 variables are used (with limited number of buckets). In addition, continues variables cannot be used for adjustment (unless bucketed). A more general approach is the inverse propensity score weighting (ipw). ","version":"Next","tagName":"h2"},{"title":"Methodology​","type":1,"pageTitle":"Post-Stratification","url":"/docs/docs/statistical_methods/poststratify/#methodology","content":"The idea behind post-stratification is simple. For each cell (strata) in the population, compute the percent of the total population in this cell. Then fit weights so that they adjust the sample so to have the same proportions for each strata as in the population. We will illustrate this with an example. Assume that we have sampled people from a certain population to a survey and asked for their age and gender so to use these for weighing. Assume also that the joint distribution of age and gender in this population is known from a census, and is the following: \tYoung adults\tAdults\tTotalFemale\t120\t380\t500 Male\t80\t420\t500 Total\t200\t800\t1000 In addition, assume that for the specific survey we ran young adults tend to reply more, so that the distribution of responses in the survey is the following: \tYoung adults\tAdults\tTotalFemale\t30\t10\t40 Male\t50\t10\t60 Total\t80\t20\t100 The post-stratification weights are then computed as follows: Proportion of Female young adults in the population is 120/1000=0.12120/1000 = 0.12120/1000=0.12Proportion of Female young adults in the sample is 30/100=0.330/100 = 0.330/100=0.3 Inflation factor - this is the inverse probability factor indicating by how much we need to multiply the total sample size to get to the total population size. It is equal to population size / sample size. In our case it is: 1000/100=101000/100 = 101000/100=10. Calculate weights for each Female young adult in the sample: (population %) / (sample %) (inflation factor). In our example this is: $0.12/0.3 10= 0.4 * 10= 4$. This means that the assigned weight of each Female young adult in the sample is 4. Similarly, we can compute the weight for people from each cell in the table: \tYoung adults\tAdultsFemale\t0.12/0.3∗10=40.12/0.3 * 10 = 40.12/0.3∗10=4\t0.38/0.1∗10=380.38/0.1 * 10 = 380.38/0.1∗10=38 Male\t0.08/0.5∗10=1.60.08/0.5 * 10 = 1.60.08/0.5∗10=1.6\t0.42/0.1∗10=420.42/0.1 *10 = 420.42/0.1∗10=42 ","version":"Next","tagName":"h2"},{"title":"References​","type":1,"pageTitle":"Post-Stratification","url":"/docs/docs/statistical_methods/poststratify/#references","content":"More about post-stratification: Introduction to post-stratificationKolenikov, Stas. 2016. “Post-Stratification or Non-Response Adjustment?” Survey Practice 9 (3). https://doi.org/10.29115/SP-2016-0014. ","version":"Next","tagName":"h2"},{"title":"Inverse Propensity Score Weighting","type":0,"sectionRef":"#","url":"/docs/docs/statistical_methods/ipw/","content":"","keywords":"inverse propensity score weighting ipw ipsw","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Inverse Propensity Score Weighting","url":"/docs/docs/statistical_methods/ipw/#introduction","content":"The inverse propensity score weighting is a statistical method to adjust a non-random sample to represent a population by weighting the sample units. It assumes two samples: (1) A sample of respondents to a survey (or in a more general framework, a biased panel), will be referred to as &quot;sample&quot;. (2) A sample of a target population, often referred to as &quot;reference sample&quot; or &quot;reference survey&quot; [1], will be referred to as &quot;target&quot;. This sample includes a larger coverage of the population or a better sampling properties in a way that represents the population better. It often includes only a limited number of covariates and doesn't include the outcome variables (the survey responses). In different cases it can be the whole target population (in case it is available), a census data (based on a survey) or an existing survey. ","version":"Next","tagName":"h2"},{"title":"Mathematical model​","type":1,"pageTitle":"Inverse Propensity Score Weighting","url":"/docs/docs/statistical_methods/ipw/#mathematical-model","content":"Let SSS represent the sample of respondents, with nnn units, and TTT represent the target population, with NNN units. We may assume each unit iii in the sample and target have a base weight, which is referred to as a design weight, did_idi​. These are often set to be 1 for the sample (assuming unknown sampling probabilities), and are based on the sampling procedure for the target. In addition, we assume all units in sample and target have a covariates vector attached, xix_ixi​. Note that we assume that the same covariates are available for the sample and the target, otherwise we ignore the non-overlapping covariates. Define the propensity score as the probability to be included in the sample (the respondents group) conditioned on the characteristics of the unit, i.e. let pi=Pr{i∈S∣xi}p_i = Pr\\{i \\in S | x_i\\}pi​=Pr{i∈S∣xi​}, i=1...ni=1...ni=1...n. pip_ipi​ is then estimated using logistic regression, assuming a linear relation between the covariates and the logit of the probability: ln⁡(pi1−pi)=β0+β1xi\\ln(\\frac{p_i}{1-p_i})=\\beta_0+\\beta_1 x_iln(1−pi​pi​​)=β0​+β1​xi​. Note that balance's implementation for ipw uses a regularized logistic model through using LASSO (by using glmnet-python). This is in order to keep the inflation of the variance as minimal as possible while still addressing the meaningful differences in the covariates between the sample and the target. ","version":"Next","tagName":"h2"},{"title":"How are the regularization parameter and trimming ratio parameter chosen?​","type":1,"pageTitle":"Inverse Propensity Score Weighting","url":"/docs/docs/statistical_methods/ipw/#how-are-the-regularization-parameter-and-trimming-ratio-parameter-chosen","content":"There are two options to choose the regularization parameter and trimming ratio parameter in balance: Bounding the design effect by setting max_de = X. In this case the regularization parameter and the trimming ratio parameter are chosen by a grid search over the 10 models with the largest design effect. This is based on the assumption that a larger design effect often implies better covariate balancing. Within these 10 models, the model with the smallest ASMD is chosen. Choosing the regularization parameter by the &quot;1se rule&quot; (or &quot;One Standard Error Rule&quot;) of cross validation, i.e. the largest penalty factor λ\\lambdaλ at which the MSE is at most 1 standard error from the minimal MSE . This is applied when max_de is set to None. In this case the trimming ratio parameter is set by the user, and default to 20. ","version":"Next","tagName":"h3"},{"title":"Weights estimation​","type":1,"pageTitle":"Inverse Propensity Score Weighting","url":"/docs/docs/statistical_methods/ipw/#weights-estimation","content":"The estimated propensity scores are then used to estimate the weights of the sample by setting wi=1−pipidiw_i = \\frac{1-p_i}{p_i} d_iwi​=pi​1−pi​​di​. ","version":"Next","tagName":"h3"},{"title":"References​","type":1,"pageTitle":"Inverse Propensity Score Weighting","url":"/docs/docs/statistical_methods/ipw/#references","content":"[1] Lee, S., &amp; Valliant, R. (2009). Estimation for volunteer panel web surveys using propensity score adjustment and calibration adjustment. Sociological Methods &amp; Research, 37(3), 319-343. More about Inverse Probability Weighting in Wikipedia. ","version":"Next","tagName":"h2"},{"title":"Raking","type":0,"sectionRef":"#","url":"/docs/docs/statistical_methods/rake/","content":"","keywords":"rake raking","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Raking","url":"/docs/docs/statistical_methods/rake/#introduction","content":"Raking, also known as iterative proportional fitting, is a statistical technique widely used in survey sampling to adjust weights and enhance the representativeness of the collected data. When a sample is drawn from a population, there might be differences in the distribution of certain variables between the sample and the population. Raking, similar to other methods in the balance package, helps to account for these differences, making the sample's distribution closely resemble that of the population. Raking is an iterative process that involves adjusting the weights of sampled units based on the marginal distributions of certain variables in the population. Typically, we have access to such marginal distributions, but not their combined joint distribution. The variables chosen for raking are usually demographic variables, such as age, gender, education, income, and other socioeconomic variables, which are known to influence survey outcomes. By adjusting the weights of the sampled units, raking helps to correct for potential biases that may arise due to nonresponse, undercoverage, or oversampling of certain groups. ","version":"Next","tagName":"h2"},{"title":"Methodology​","type":1,"pageTitle":"Raking","url":"/docs/docs/statistical_methods/rake/#methodology","content":"Raking essentially applies post-stratification repeatedly over all the covariates. For example, we may have the marginal distribution of age*gender and education. Raking would first adjust weights to match the age*gender distribution and then take these weights as input to adjust for education. It would then adjust again to age*gender and then again to education, and so forth. This process will repeat until either a max_iteration is met, or the weights have converged and no longer seem to change from one iteration to another. Raking is a valuable technique for addressing potential biases and enhancing the representativeness of survey data. By iteratively adjusting the weights of sampled units based on the marginal distribution of key variables, raking ensures that survey estimates are more accurate and reliable. You can see a detailed example of how to perform raking in balance in the tutorial: quickstart_rake. ","version":"Next","tagName":"h2"},{"title":"References​","type":1,"pageTitle":"Raking","url":"/docs/docs/statistical_methods/rake/#references","content":"https://en.wikipedia.org/wiki/Rakinghttps://www.pewresearch.org/methods/2018/01/26/how-different-weighting-methods-work/Practical Considerations in Raking Survey Data (url) ","version":"Next","tagName":"h2"},{"title":"balance: a python package for balancing biased data samples","type":0,"sectionRef":"#","url":"/docs/docs/overview/","content":"","keywords":"","version":"Next"},{"title":"What is balance?​","type":1,"pageTitle":"balance: a python package for balancing biased data samples","url":"/docs/docs/overview/#what-is-balance","content":"balance is a Python package offering a simple workflow and methods for dealing with biased data samples when looking to infer from them to some population of interest. Biased samples often occur in survey statistics when respondents present non-response bias or survey suffers from sampling bias (that are not missing completely at random). A similar issue arises in observational studies when comparing the treated vs untreated groups, and in any data that suffers from selection bias. Under the missing at random assumption (MAR), bias in samples could sometimes be (at least partially) mitigated by relying on auxiliary information (a.k.a.: &quot;covariates&quot; or &quot;features&quot;) that is present for all items in the sample, as well as present in a sample of items from the population. For example, if we want to infer from a sample of respondents to some survey, we may wish to adjust for non-response using demographic information such as age, gender, education, etc. This can be done by weighing the sample to the population using auxiliary information. The package is intended for researchers who are interested in balancing biased samples, such as the ones coming from surveys, using a Python package. This need may arise by survey methodologists, demographers, UX researchers, market researchers, and generally data scientists, statisticians, and machine learners. More about the methodological background can be found in Sarig, T., Galili, T., &amp; Eilat, R. (2023). balance – a Python package for balancing biased data samples. Installation ","version":"Next","tagName":"h2"},{"title":"Requirements​","type":1,"pageTitle":"balance: a python package for balancing biased data samples","url":"/docs/docs/overview/#requirements","content":"You need Python 3.9, 3.10, 3.11, or 3.12 to run balance. balance can be built and run from Linux, OSX, and Windows. The required Python dependencies are: REQUIRES = [ # Numpy and pandas: carefully versioned for binary compatibility &quot;numpy&gt;=1.21.0,&lt;2.0; python_version&lt;'3.12'&quot;, &quot;numpy&gt;=1.24.0,&lt;2.1; python_version&gt;='3.12'&quot;, &quot;pandas&gt;=1.5.0,&lt;2.4.0; python_version&lt;'3.12'&quot;, &quot;pandas&gt;=2.0.0,&lt;2.4.0; python_version&gt;='3.12'&quot;, # Scientific stack &quot;scipy&gt;=1.7.0,&lt;1.14.0; python_version&lt;'3.12'&quot;, &quot;scipy&gt;=1.11.0,&lt;1.14.0; python_version&gt;='3.12'&quot;, &quot;scikit-learn&gt;=1.0.0,&lt;1.4.0; python_version&lt;'3.12'&quot;, &quot;scikit-learn&gt;=1.3.0,&lt;1.5.0; python_version&gt;='3.12'&quot;, &quot;ipython&quot;, &quot;patsy&quot;, &quot;seaborn&quot;, &quot;plotly&quot;, &quot;matplotlib&quot;, &quot;statsmodels&quot;, &quot;ipfn&quot;, &quot;session-info&quot;, ]  See setup.py for more details. ","version":"Next","tagName":"h2"},{"title":"Installing balance​","type":1,"pageTitle":"balance: a python package for balancing biased data samples","url":"/docs/docs/overview/#installing-balance","content":"","version":"Next","tagName":"h2"},{"title":"Installing via PyPi​","type":1,"pageTitle":"balance: a python package for balancing biased data samples","url":"/docs/docs/overview/#installing-via-pypi","content":"We recommend installing balance from PyPi via pip for the latest stable version: python -m pip install balance  Installation will use Python wheels from PyPI, available for OSX, Linux, and Windows. ","version":"Next","tagName":"h3"},{"title":"Installing from Source/Git​","type":1,"pageTitle":"balance: a python package for balancing biased data samples","url":"/docs/docs/overview/#installing-from-sourcegit","content":"You can install the latest (bleeding edge) version from Git: python -m pip install git+https://github.com/facebookresearch/balance.git  Alternatively, if you have a local clone of the repo: cd balance python -m pip install .  Getting started ","version":"Next","tagName":"h3"},{"title":"balance's workflow in high-level​","type":1,"pageTitle":"balance: a python package for balancing biased data samples","url":"/docs/docs/overview/#balances-workflow-in-high-level","content":"The core workflow in balance deals with fitting and evaluating weights to a sample. For each unit in the sample (such as a respondent to a survey), balance fits a weight that can be (loosely) interpreted as the number of people from the target population that this respondent represents. This aims to help mitigate the coverage and non-response biases, as illustrated in the following figure.  The weighting of survey data through balance is done in the following main steps: Loading data of the respondents of the survey.Loading data about the target population we would like to correct for.Diagnostics of the sample covariates so to evaluate whether weighting is needed.Adjusting the sample to the target.Evaluation of the results.Use the weights for producing population level estimations.Saving the output weights. You can see a step-by-step description (with code) of the above steps in the General Framework page. ","version":"Next","tagName":"h2"},{"title":"Code example of using balance​","type":1,"pageTitle":"balance: a python package for balancing biased data samples","url":"/docs/docs/overview/#code-example-of-using-balance","content":"You may run the following code to play with balance's basic workflow (these are snippets taken from the quickstart tutorial): We start by loading data, and adjusting it: from balance import load_data, Sample # load simulated example data target_df, sample_df = load_data() # Import sample and target data into a Sample object sample = Sample.from_frame(sample_df, outcome_columns=[&quot;happiness&quot;]) target = Sample.from_frame(target_df) # Set the target to be the target of sample sample_with_target = sample.set_target(target) # Check basic diagnostics of sample vs target before adjusting: # sample_with_target.covars().plot()  You can read more on evaluation of the pre-adjusted data in the Pre-Adjustment Diagnostics page. Next, we adjust the sample to the population by fitting balancing survey weights: # Using ipw to fit survey weights adjusted = sample_with_target.adjust()  You can read more on adjustment process in the Adjusting Sample to Population page. The above code gets us an adjusted object with weights. We can evaluate the benefit of the weights to the covariate balance, for example by running: print(adjusted.summary()) # Covar ASMD reduction: 62.3%, design effect: 2.249 # Covar ASMD (7 variables):0.335 -&gt; 0.126 # Model performance: Model proportion deviance explained: 0.174 adjusted.covars().plot(library = &quot;seaborn&quot;, dist_type = &quot;kde&quot;)  And get:  We can also check the impact of the weights on the outcome using: # For the outcome: print(adjusted.outcomes().summary()) # 1 outcomes: ['happiness'] # Mean outcomes: # happiness # source # self 54.221388 # unadjusted 48.392784 # # Response rates (relative to number of respondents in sample): # happiness # n 1000.0 # % 100.0 adjusted.outcomes().plot()   You can read more on evaluation of the post-adjusted data in the Evaluating and using the adjustment weights page. Finally, the adjusted data can be downloaded using: adjusted.to_download() # Or: # adjusted.to_csv()  To see a more detailed step-by-step code example with code output prints and plots (both static and interactive), please go over to the tutorials section. ","version":"Next","tagName":"h2"},{"title":"Implemented methods for adjustments​","type":1,"pageTitle":"balance: a python package for balancing biased data samples","url":"/docs/docs/overview/#implemented-methods-for-adjustments","content":"balance currently implements various adjustment methods. Click the links to learn more about each: Logistic regression using L1 (LASSO) penalization.Covariate Balancing Propensity Score (CBPS).Post-stratification.Raking. ","version":"Next","tagName":"h2"},{"title":"Implemented methods for diagnostics/evaluation​","type":1,"pageTitle":"balance: a python package for balancing biased data samples","url":"/docs/docs/overview/#implemented-methods-for-diagnosticsevaluation","content":"For diagnostics the main tools (comparing before, after applying weights, and the target population) are: Plots barplotsdensity plots (for weights and covariances)qq-plots Statistical summaries Weights distributions Kish's design effectMain summaries (mean, median, variances, quantiles) Covariate distributions Absolute Standardized Mean Difference (ASMD). For continuous variables, it is Cohen's d. Categorical variables are one-hot encoded, Cohen's d is calculated for each category and ASMD for a categorical variable is defined as Cohen's d, average across all categories. You can read more on evaluation of the post-adjusted data in the Evaluating and using the adjustment weights page. ","version":"Next","tagName":"h2"},{"title":"Other resources​","type":1,"pageTitle":"balance: a python package for balancing biased data samples","url":"/docs/docs/overview/#other-resources","content":"Presentation: &quot;Balancing biased data samples with the 'balance' Python package&quot; - presented in the Israeli Statistical Association (ISA) conference on June 1st 2023. More details ","version":"Next","tagName":"h2"},{"title":"Getting help, submitting bug reports and contributing code​","type":1,"pageTitle":"balance: a python package for balancing biased data samples","url":"/docs/docs/overview/#getting-help-submitting-bug-reports-and-contributing-code","content":"You are welcome to: Learn more in the balance website.Ask for help on: https://stats.stackexchange.com/questions/tagged/balanceSubmit bug-reports and features' suggestions at: https://github.com/facebookresearch/balance/issuesSend a pull request on: https://github.com/facebookresearch/balance. See the CONTRIBUTING file for how to help out. And our CODE OF CONDUCT for our expectations from contributors. ","version":"Next","tagName":"h2"},{"title":"Citing balance​","type":1,"pageTitle":"balance: a python package for balancing biased data samples","url":"/docs/docs/overview/#citing-balance","content":"Sarig, T., Galili, T., &amp; Eilat, R. (2023). balance – a Python package for balancing biased data samples. https://arxiv.org/abs/2307.06024 BibTeX: @misc{sarig2023balance, title={balance - a Python package for balancing biased data samples}, author={Tal Sarig and Tal Galili and Roee Eilat}, year={2023}, eprint={2307.06024}, archivePrefix={arXiv}, primaryClass={stat.CO} } ","version":"Next","tagName":"h2"},{"title":"License​","type":1,"pageTitle":"balance: a python package for balancing biased data samples","url":"/docs/docs/overview/#license","content":"The balance package is licensed under the MIT license, and all the documentation on the site (including text and images) is under CC-BY. News You can follow updates on our: BlogChangelog ","version":"Next","tagName":"h2"},{"title":"Acknowledgements / People​","type":1,"pageTitle":"balance: a python package for balancing biased data samples","url":"/docs/docs/overview/#acknowledgements--people","content":"The balance package is actively maintained by people from the Central Applied Science team (in Menlo Park and Tel Aviv), by Wesley Lee, Tal Sarig, and Tal Galili. The balance package was (and is) developed by many people, including: Roee Eilat, Tal Galili, Daniel Haimovich, Kevin Liou, Steve Mandala, Adam Obeng (author of the initial internal Meta version), Tal Sarig, Luke Sonnet, Sean Taylor, Barak Yair Reif, and others. If you worked on balance in the past, please email us to be added to this list. The balance package was open-sourced by Tal Sarig, Tal Galili and Steve Mandala in late 2022. Branding created by Dana Beaty, from the Meta AI Design and Marketing Team. For logo files, see here. ","version":"Next","tagName":"h2"},{"title":"Tutorials and notebooks Overview","type":0,"sectionRef":"#","url":"/docs/tutorials/","content":"","keywords":"","version":"Next"},{"title":"Tutorials list (more tutorials to be added soon):​","type":1,"pageTitle":"Tutorials and notebooks Overview","url":"/docs/tutorials/#tutorials-list-more-tutorials-to-be-added-soon","content":"quickstart - this is based on a simulated data and presents the simple end-to-end workflow of balance package with default arguments. It demonstrates the process from reading the data, through understanding the biases in the sample, producing weights, evaluating the results and producing the population estimations.quickstart_cbps - like the quickstart tutorial, but shows how to use the CBPS algorithm and compares the results to IPW (logistic regression with LASSO).quickstart_rake - like the quickstart tutorial, but shows how to use the rake (raking) algorithm and compares the results to IPW (logistic regression with LASSO).balance_transformations_and_formulas - This tutorial showcases ways in which transformations, formulas and penalty can be included in your pre-processing of the covariates before adjusting for them.comparing_cbps_in_r_vs_python_using_sim_data - This notebook compares the results of running CBPS in R and Python. In R using the BCPS package, and in Python using the balance package. The results are almost identical. ","version":"Next","tagName":"h2"},{"title":"Covariate Balancing Propensity Score (CBPS)","type":0,"sectionRef":"#","url":"/docs/docs/statistical_methods/cbps/","content":"","keywords":"Covariate Balancing Propensity Score cbps","version":"Next"},{"title":"References and implementation​","type":1,"pageTitle":"Covariate Balancing Propensity Score (CBPS)","url":"/docs/docs/statistical_methods/cbps/#references-and-implementation","content":"Reference: Imai, K., &amp; Ratkovic, M. (2014). Covariate balancing propensity score. Journal of the Royal Statistical Society: Series B: Statistical Methodology, 243-263. (link) R package: https://cran.r-project.org/web/packages/CBPS/ (github repo ) The implementation of CBPS in balance is based on the R package, but is enhanced so to match balance's workflow by adding: features transformations, ability to bound the design effect by running a constrained optimization, and weight trimming. For the implementation in balance see code. The CBPS implementation in balance was written by Luke Sonnet and Tal Sarig. ","version":"Next","tagName":"h2"},{"title":"Introduction​","type":1,"pageTitle":"Covariate Balancing Propensity Score (CBPS)","url":"/docs/docs/statistical_methods/cbps/#introduction","content":"Goal: Estimate the propensity score that will also result in maximizing the covariate balance. Background: When estimating propensity score, there is often a process of adjusting the model and choosing the covariates for better covariate balancing. The goal of CBPS is to allow the researcher to avoid this iterative process and suggest an estimator that is optimizing both the propensity score and the balance of the covariates together. Advantages of this method over propensity score methods: Preferable in the cases of misspecification of the propensity score model, which may lead to a bias in the estimated measure.Simple to adjust and extend to other settings in causal inference.Inherits theoretical properties of GMM (generalized method of moments) and EL (empirical likelihood), which offers some theoretical guarantees of the method. ","version":"Next","tagName":"h2"},{"title":"Methodology​","type":1,"pageTitle":"Covariate Balancing Propensity Score (CBPS)","url":"/docs/docs/statistical_methods/cbps/#methodology","content":"A full description of the methodology and details are described in Imai and Ratkovic (2014). We provide here a short description of the methodology. Consider a sample of respondents of size nnn and a random sample from a target populaiton of size NNN. For each i∈Sample∪Targeti \\in Sample \\cup Targeti∈Sample∪Target, let IiI_iIi​ be the indicator for inclusion in sample (0 for target and 1 for sample) and XiX_iXi​ be a vector of observed covariates. The propensity score is defined as the conditional probability of being included in the sample conditioned on the covariates, P(Ii=1∣Xi=x)P(I_i=1 | X_i=x)P(Ii​=1∣Xi​=x). Let YiY_iYi​ be the potential outcome observed only for i∈Samplei\\in Samplei∈Sample. ","version":"Next","tagName":"h2"},{"title":"Assumptions​","type":1,"pageTitle":"Covariate Balancing Propensity Score (CBPS)","url":"/docs/docs/statistical_methods/cbps/#assumptions","content":"The propensity is bounded away from 0 and 1 (all individuals have a theoretical probability to be in the respondents group): 0&lt;P(Ii=1∣Xi=x)&lt;10&lt;P(I_i=1 | X_i=x)&lt;10&lt;P(Ii​=1∣Xi​=x)&lt;1 for all xxx.Ignorability assumption: ((Yi(0),Yi(1))⊥Ii)∣Xi({(Y_i(0), Y_i(1))}\\perp I_i) | X_i((Yi​(0),Yi​(1))⊥Ii​)∣Xi​, where Yi(0)Y_i(0)Yi​(0) indicates the response of unit iii if it is from the sample, and Yi(1)Y_i(1)Yi​(1) indicates the hypothetical response of unit iii if it is from the target population. Rosenbaum and Rubin (1983) [2] showed that this assumption implies that the outcome is independent of the inclusion in the sample given the (theoretical) propensity score (this is the &quot;dimension reduction&quot; property of the propensity score). I.e.: ((Yi(0),Yi(1))⊥Ii)∣P(Ii=1∣Xi=x)({(Y_i(0), Y_i(1))}\\perp I_i) | P(I_i=1 | X_i=x)((Yi​(0),Yi​(1))⊥Ii​)∣P(Ii​=1∣Xi​=x). ","version":"Next","tagName":"h3"},{"title":"Recap - Propensity score estimation​","type":1,"pageTitle":"Covariate Balancing Propensity Score (CBPS)","url":"/docs/docs/statistical_methods/cbps/#recap---propensity-score-estimation","content":"Using a logistic regression model, the propensity score is modeled by: πβ(Xi)=P(Ii=1∣Xi=x)=exp⁡(XiTβ)1+exp⁡(XiTβ)\\pi _\\beta(X_i)=P(I_i=1|X_i=x)=\\frac{\\exp(X_i ^T \\beta)}{1+\\exp(X_i ^T \\beta)}πβ​(Xi​)=P(Ii​=1∣Xi​=x)=1+exp(XiT​β)exp(XiT​β)​ for all i∈Samplei \\in Samplei∈Sample. This is estimated by maximizing the log-likelihood, which results in: β^MLE=arg⁡max⁡β∑i=1nIilog⁡(πβ(Xi))+(1−Ii)log⁡(1−πβ(Xi))\\hat{\\beta}_{MLE}=\\arg\\max_\\beta \\sum_{i=1}^n I_i\\log(\\pi_\\beta(X_i))+(1-I_i)\\log(1-\\pi_\\beta(X_i))β^​MLE​=argβmax​i=1∑n​Ii​log(πβ​(Xi​))+(1−Ii​)log(1−πβ​(Xi​)) which implies the first order condition: 1n∑i=1n[Iiπβ′(Xi)πβ(Xi)+(1−Ii)πβ′(Xi)1−πβ(Xi)]=0\\frac{1}{n}\\sum_{i=1}^n \\left[ \\frac{I_i\\pi^\\prime_\\beta(X_i)}{\\pi_\\beta(X_i)} +\\frac{(1-I_i)\\pi^\\prime_\\beta(X_i)}{1-\\pi_\\beta(X_i)}\\right]=0n1​i=1∑n​[πβ​(Xi​)Ii​πβ′​(Xi​)​+1−πβ​(Xi​)(1−Ii​)πβ′​(Xi​)​]=0 where the derivative of π\\piπ is by βT\\beta^TβT. This condition can be viewed as a condition that balances a certain function of the covariates, in this case the derivative of the propensity score πβ′(Xi)\\pi^\\prime_\\beta(X_i)πβ′​(Xi​). ","version":"Next","tagName":"h3"},{"title":"CBPS​","type":1,"pageTitle":"Covariate Balancing Propensity Score (CBPS)","url":"/docs/docs/statistical_methods/cbps/#cbps","content":"Generally, we can expand the above to hold for any function fff: E{Iif(Xi)πβ(Xi)+(1−Ii)f(Xi)1−πβ(Xi)}=0\\mathbb{E} \\left\\{ \\frac{I_if(X_i)}{\\pi_\\beta(X_i)} +\\frac{(1-I_i)f(X_i)}{1-\\pi_\\beta(X_i)}\\right\\} =0E{πβ​(Xi​)Ii​f(Xi​)​+1−πβ​(Xi​)(1−Ii​)f(Xi​)​}=0 (given the expectation exists). CBPS chooses f(x)=xf(x)=xf(x)=x as the balancing function fff in addition to the traditional logistic regression condition (this is what implemented in R and in balance), but generally any function the researcher may choose could be used here. The function f(x)=xf(x)=xf(x)=x results in balancing the first moment of each covariate ","version":"Next","tagName":"h3"},{"title":"Estimation of CBPS​","type":1,"pageTitle":"Covariate Balancing Propensity Score (CBPS)","url":"/docs/docs/statistical_methods/cbps/#estimation-of-cbps","content":"The estimation is done by using Generalized Methods of Moments (GMM):Given moments conditions of the form E{g(Xi,θ)}=0\\mathbb{E}\\{g(X_i,\\theta)\\}=0E{g(Xi​,θ)}=0, the optimal solution minimizes the norm of the sample analog, 1n∑i=1ng(xi,θ)\\frac{1}{n}\\sum_{i=1}^n g(x_i,\\theta)n1​∑i=1n​g(xi​,θ), with respect to θ\\thetaθ. This results in an estimator of the form: θ^=arg⁡min⁡θ1n∑i=1ngT(xi,θ)Wg(xi,θ),\\hat{\\theta}=\\arg\\min_\\theta \\frac{1}{n}\\sum_{i=1}^n g^T(x_i,\\theta)Wg(x_i,\\theta),θ^=argθmin​n1​i=1∑n​gT(xi​,θ)Wg(xi​,θ), where WWW is semi-definite positive matrix, often chosen to be the variance matrix W(θ)=(1n∑i=1ng(xi,θ)gT(xi,θ))−1W(\\theta)=\\left(\\frac{1}{n}\\sum_{i=1}^n g(x_i,\\theta)g^T(x_i,\\theta)\\right)^{-1}W(θ)=(n1​∑i=1n​g(xi​,θ)gT(xi​,θ))−1 (which is unknown). This can be solved by iterative algorithm, by starting with W^=I\\hat{W}=IW^=I, computing θ^\\hat{\\theta}θ^ and W(θ^)W(\\hat{\\theta})W(θ^), and so on (for two-step GMM, we stop after optimizing to θ^\\hat{\\theta}θ^). Alternatively, it can be solved by Continuously updating GMM algorithm, which estimate θ^\\hat{\\theta}θ^ and W^\\hat{W}W^ on the same time. The model is over-identified if the number of equations is larger than the number of parameters. For CBPS, the sample analog for the covariate balancing moment condition is:1n∑i=1n[Iixiπβ(xi)+(1−Ii)xi1−πβ(xi)]\\frac{1}{n}\\sum_{i=1}^n\\left[\\frac{I_ix_i}{\\pi_\\beta(x_i)} +\\frac{(1-I_i)x_i}{1-\\pi_\\beta(x_i)}\\right]n1​∑i=1n​[πβ​(xi​)Ii​xi​​+1−πβ​(xi​)(1−Ii​)xi​​], which can be written as 1n∑i=1nIi−πβ(Xi)πβ(xi)(1−πβ(xi))xi=0\\frac{1}{n}\\sum_{i=1}^n\\frac{I_i-\\pi_\\beta(X_i)}{\\pi_\\beta(x_i)(1-\\pi_\\beta(x_i))}x_i=0n1​∑i=1n​πβ​(xi​)(1−πβ​(xi​))Ii​−πβ​(Xi​)​xi​=0 (for Ii∈{0,1}I_i\\in\\{0,1\\}Ii​∈{0,1}). Let gi(Ii,Xi)=(Ii−πβ(Xi)πβ(Xi)(1−πβ(Xi))πβ′(Xi) Ii−πβ(Xi)πβ(Xi)(1−πβ(Xi))Xi )g_i(I_i,X_i)=\\left(\\begin{matrix} \\frac{I_i-\\pi_\\beta(X_i)}{\\pi_\\beta(X_i)(1-\\pi_\\beta(X_i))}\\pi^\\prime_\\beta(X_i)\\ \\\\ \\frac{I_i-\\pi_\\beta(X_i)}{\\pi_\\beta(X_i)(1-\\pi_\\beta(X_i))} X_i\\ \\end{matrix}\\right)gi​(Ii​,Xi​)=(πβ​(Xi​)(1−πβ​(Xi​))Ii​−πβ​(Xi​)​πβ′​(Xi​) πβ​(Xi​)(1−πβ​(Xi​))Ii​−πβ​(Xi​)​Xi​ ​) be the vector representing the moments we would like to solve. This contains the two conditions of maximizing the log-likelihood and balancing the covariates. Note that this is over-identified, since the number of equations is larger then the number of parameters. Another option is to consider the “just-identified” (&quot;exact&quot;) CBPS, where we consider only the covariate balancing conditions and not the propensity score condition. Using GMM, we have β^=arg⁡min⁡βgˉTΣβ−1gˉ\\hat{\\beta}=\\arg\\min_\\beta \\bar{g}^T \\Sigma^{-1}_\\beta \\bar{g}β^​=argβmin​gˉ​TΣβ−1​gˉ​ where gˉ=1n∑i=1ngi\\bar{g}=\\frac{1}{n}\\sum_{i=1}^n g_igˉ​=n1​∑i=1n​gi​ and Σβ=E[1n∑i=1ngigiT∣Xi]\\Sigma_\\beta=\\mathbb{E}\\left[\\frac{1}{n}\\sum_{i=1}^n g_i g^T_i | X_i\\right]Σβ​=E[n1​∑i=1n​gi​giT​∣Xi​], which can be estimated by Σ^β=1n∑i=1n(πβ(Xi)(1−πβ(Xi))XiXiTXiXiTXiXiTπβ(Xi)(1−πβ(Xi))XiXiT)\\hat{\\Sigma}_\\beta=\\frac{1}{n}\\sum_{i=1}^n \\left( \\begin{matrix} \\pi_\\beta(X_i)(1-\\pi_\\beta(X_i))X_iX_i^T &amp; X_i X_i^T \\\\ X_iX_i^T &amp; \\pi_\\beta(X_i)(1-\\pi_\\beta(X_i))X_iX_i^T \\end{matrix} \\right)Σ^β​=n1​i=1∑n​(πβ​(Xi​)(1−πβ​(Xi​))Xi​XiT​Xi​XiT​​Xi​XiT​πβ​(Xi​)(1−πβ​(Xi​))Xi​XiT​​) To optimize this, we use the two-step GMM, using gradient-based optimization, starting with βMLE\\beta^{MLE}βMLE (from the original logistic regression): β0=β^MLE\\beta_0=\\hat{\\beta}_{MLE}β0​=β^​MLE​W^0=Σβ0−1\\hat{W}_0=\\Sigma_{\\beta_0}^{-1}W^0​=Σβ0​−1​β^=arg⁡min⁡βgˉTW^β^0gˉ\\hat{\\beta}=\\arg\\min_\\beta \\bar{g}^T\\hat{W}_{\\hat{\\beta}_0}\\bar{g}β^​=argminβ​gˉ​TW^β^​0​​gˉ​ - use gradient based optimization ","version":"Next","tagName":"h3"},{"title":"References​","type":1,"pageTitle":"Covariate Balancing Propensity Score (CBPS)","url":"/docs/docs/statistical_methods/cbps/#references","content":"[1] Imai, K., &amp; Ratkovic, M. (2014). Covariate balancing propensity score. Journal of the Royal Statistical Society: Series B: Statistical Methodology, 243-263. [2] PAUL R. ROSENBAUM, DONALD B. RUBIN, The central role of the propensity score in observational studies for causal effects, Biometrika, Volume 70, Issue 1, April 1983, Pages 41–55, https://doi.org/10.1093/biomet/70.1.41 ","version":"Next","tagName":"h2"}]