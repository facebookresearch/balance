"use strict";(globalThis.webpackChunkstaticdocs_starter=globalThis.webpackChunkstaticdocs_starter||[]).push([[5894],{76042(e){e.exports=JSON.parse('{"blogPosts":[{"id":"/2026/01/20/balance-0-15-0","metadata":{"permalink":"/blog/2026/01/20/balance-0-15-0","source":"@site/blog/2026/01/20/balance-0-15-0.md","title":"Balance v0.15.0 - more sklearn models, diagnostics, and stability (100% test-coverage!)","description":"\ud83c\udf89 balance v0.15.0 is out!","date":"2026-01-20T00:00:00.000Z","formattedDate":"January 20, 2026","tags":[{"label":"python","permalink":"/blog/tags/python"},{"label":"open-source","permalink":"/blog/tags/open-source"},{"label":"survey-statistics","permalink":"/blog/tags/survey-statistics"},{"label":"package-update","permalink":"/blog/tags/package-update"}],"readingTime":6.06,"hasTruncateMarker":true,"authors":[{"name":"Soumyadip Sarkar","title":"Independent Researcher","url":"https://www.linkedin.com/in/neuralsorcerer"},{"name":"Tal Galili","title":"Machine Learning Engineer","url":"https://www.linkedin.com/in/tal-galili-5993085/"}],"frontMatter":{"title":"Balance v0.15.0 - more sklearn models, diagnostics, and stability (100% test-coverage!)","authors":[{"name":"Soumyadip Sarkar","title":"Independent Researcher","url":"https://www.linkedin.com/in/neuralsorcerer"},{"name":"Tal Galili","title":"Machine Learning Engineer","url":"https://www.linkedin.com/in/tal-galili-5993085/"}],"tags":["python","open-source","survey-statistics","package-update"],"hide_table_of_contents":true},"nextItem":{"title":"Balance in motion - v0.12.0 expands Python version support, visualizations, and statistical methods","permalink":"/blog/2025/10/25/balance-0-12-0"}},"content":"\ud83c\udf89 **balance v0.15.0 is out!**\\n\\n### What is balance?\\n\\n[**balance**](https://pypi.org/project/balance/) is a Python package (from Meta) offering a simple workflow and methods for dealing with biased data samples when looking to infer from them to some population of interest. Biased samples often occur in survey statistics when respondents present non-response bias or surveys suffer from sampling bias (that are not missing completely at random). A similar issue arises in observational studies when comparing treated vs untreated groups, and in any data that suffers from selection bias.\\n\\n### Highlights from **[v0.15.0](https://pypi.org/project/balance/)** (since [v0.12.0](https://github.com/facebookresearch/balance/releases/tag/0.12.0)):\\n\\n\u2705 **More control over modeling:** The ability to run any sklearn model (instead of just LogisticRegression) to fit inverse-propensity-score weights. Plus formula-driven summaries and explicit missing-data handling.\\n\\n\u2705 **Stronger diagnostics:** The way weights influence covariate imbalance can now be evaluated not just with ASMD (as before), but also with various distribution distance metrics (KLD, EMD, CVMD, KS).\\n\\n\u2705 **Reliable code:** Test coverage was increased to 100%, with full type-checking across the whole codebase. Plus CLI enhancements and improved docs/tutorials.\\n\\n[![balance_logo_horizontal](https://raw.githubusercontent.com/facebookresearch/balance/main/website/static/img/balance_logo/PNG/Horizontal/balance_Logo_Horizontal_FullColor_RGB.png)](https://import-balance.org/)\\n\\n\x3c!--truncate--\x3e\\n\\n## Updated Tutorials\\n\\n- Post-stratification tutorial notebook (and expanded documentation): https://import-balance.org/docs/tutorials/quickstart_poststratify/\\n- CLI tutorial: https://import-balance.org/docs/tutorials/balance_cli_tutorial/\\n- Customizing IPW models: https://import-balance.org/docs/tutorials/quickstart/\\n\\n\\n## More Flexible IPW Modeling and Summary Tools\\n\\n### Bring Your Own IPW sklearn Estimator\\n\\n`.adjust(method=\\"ipw\\")` now accepts **any scikit-learn classifier** via the `model` argument, so you can use estimators like random forests or gradient boosting. You can also pass a configured `LogisticRegression` instance or provide JSON-configured parameters through the CLI.\\n\\n> Examples below assume `sample` and `target` are `Sample` objects unless otherwise noted.\\n\\nExample setup used by multiple snippets:\\n\\n```python\\nimport pandas as pd\\nfrom balance.sample_class import Sample\\n\\nsample_df = pd.DataFrame(\\n    {\\n        \\"id\\": [1, 2, 3, 4],\\n        \\"age\\": [20, 30, 40, 50],\\n        \\"group\\": [\\"A\\", \\"B\\", \\"A\\", \\"B\\"],\\n        \\"outcome\\": [1.0, 2.0, 3.0, 4.0],\\n        \\"weight\\": [1.0, 1.0, 1.0, 1.0],\\n    }\\n)\\ntarget_df = pd.DataFrame(\\n    {\\n        \\"id\\": [10, 11, 12, 13, 14, 15],\\n        \\"age\\": [25, 35, 45, 55, 65, 75],\\n        \\"group\\": [\\"A\\", \\"B\\", \\"A\\", \\"B\\", \\"A\\", \\"B\\"],\\n        \\"outcome\\": [1.5, 2.5, 3.5, 4.5, 5.5, 6.5],\\n        \\"weight\\": [1.0] * 6,\\n    }\\n)\\n\\nsample = Sample.from_frame(\\n    sample_df,\\n    id_column=\\"id\\",\\n    weight_column=\\"weight\\",\\n    outcome_columns=[\\"outcome\\"],\\n    standardize_types=False,\\n)\\ntarget = Sample.from_frame(\\n    target_df,\\n    id_column=\\"id\\",\\n    weight_column=\\"weight\\",\\n    outcome_columns=[\\"outcome\\"],\\n    standardize_types=False,\\n)\\n\\nsample.df\\n```\\n\\nOutput:\\n\\n```\\n  id  age group  outcome  weight\\n0  1   20     A      1.0     1.0\\n1  2   30     B      2.0     1.0\\n2  3   40     A      3.0     1.0\\n3  4   50     B      4.0     1.0\\n```\\n\\nExample:\\n\\n```python\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\nrf = RandomForestClassifier(random_state=0)\\nadjusted = sample.adjust(target, method=\\"ipw\\", model=rf)\\n```\\n\\nA detailed example is given here: https://import-balance.org/docs/tutorials/quickstart/\\n\\n\\n## Diagnostics That Go Further\\n\\n### Beyond ASMD: New Distance Metrics\\n\\n\\nBalance now exposes **[KL divergence](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence)**, **[Earth Mover\'s Distance (EMD)](https://en.wikipedia.org/wiki/Earth_mover%27s_distance)**, **[Cram\xe9r-von Mises distance (CVMD)](https://en.wikipedia.org/wiki/Cram%C3%A9r%E2%80%93von_Mises_criterion)**, and **[Kolmogorov\u2013Smirnov (KS)](https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test)** statistics through `BalanceDF` diagnostics. These diagnostics work with weighted or unweighted comparisons, include discrete/continuous variants, and respect one-hot categorical aggregation when enabled.\\n\\nExample:\\n\\n```python\\n# Compare covariate distributions between a sample and target.\\nsample.set_target(target).covars().kld()\\nsample.set_target(target).covars().emd()\\nsample.set_target(target).covars().cvmd()\\nsample.set_target(target).covars().ks()\\n```\\n\\nOutput:\\n\\n```\\n             age  group[A]  group[B]  mean(kld)\\nindex\\ncovars  0.232348       0.0       0.0   0.116174\\n\\n         age  group[A]  group[B]  mean(emd)\\nindex\\ncovars  15.0       0.0       0.0        7.5\\n\\n             age  group[A]  group[B]  mean(cvmd)\\nindex\\ncovars  0.083333       0.0       0.0    0.041667\\n\\n        age  group[A]  group[B]  mean(ks)\\nindex\\ncovars  0.5       0.0       0.0      0.25\\n```\\n\\n### Richer Adjusted Sample Summaries\\n\\nAdjusted samples now surface more information at a glance:\\n\\n- `Sample.__str__()` shows adjustment method, trimming parameters, design effect, and effective sample size.\\n- `Sample.summary()` groups covariate diagnostics, reports design effect alongside ESSP/ESS, and surfaces weighted outcome means when available.\\n\\nExample:\\n\\n```python\\nadjusted = sample.adjust(target, method=\\"ipw\\")\\nadjusted.summary()\\n```\\n\\nOutput:\\n\\n```\\nAdjustment details:\\n    method: ipw\\n    weight trimming mean ratio: 20\\nCovariate diagnostics:\\n    Covar ASMD reduction: -3.0%\\n    Covar ASMD (3 variables): 0.401 -> 0.413\\n    Covar mean KLD reduction: 2.2%\\n    Covar mean KLD (2 variables): 0.116 -> 0.114\\nWeight diagnostics:\\n    design effect (Deff): 1.001\\n    effective sample size proportion (ESSP): 0.999\\n    effective sample size (ESS): 4.0\\nOutcome weighted means:\\n            outcome\\nsource\\nself          2.479\\nunadjusted    2.500\\ntarget        4.000\\nModel performance: Model proportion deviance explained: 0.034\\n```\\n\\n\\n\\n## Smarter Weighting Workflows\\n\\n### CLI Now Supports Outcome Columns\\n\\nThe CLI now supports `--outcome_columns`, letting you explicitly declare which columns are outcomes. Remaining columns are moved to `ignored_columns` instead of being treated implicitly.\\n\\nExample:\\n\\n```python\\nfrom argparse import Namespace\\nfrom balance.cli import BalanceCLI\\n\\nBalanceCLI(Namespace(outcome_columns=\\"y,z\\")).outcome_columns()\\n```\\n\\nOutput:\\n\\n```\\n[\'y\', \'z\']\\n```\\n\\n### High-Cardinality Covariate Warnings\\n\\nBalance warns when categorical covariates have >=80% unique values (e.g., user IDs), helping identify problematic columns before fitting.\\n\\nExample:\\n\\n```python\\n# If user_id is high-cardinality, adjust will emit a warning before fitting.\\nimport pandas as pd\\nfrom balance.utils.pandas_utils import _detect_high_cardinality_features\\n\\n_detect_high_cardinality_features(\\n    pd.DataFrame({\\"id\\": [\\"a\\", \\"b\\", \\"c\\"], \\"group\\": [\\"a\\", \\"a\\", \\"b\\"]}),\\n    threshold=0.8,\\n)\\n```\\n\\nOutput:\\n\\n```\\n[HighCardinalityFeature(column=\'id\', unique_count=3, unique_ratio=1.0, has_missing=np.False_)]\\n```\\n\\n## Developer Improvements, Bug Fixes & Breaking Changes\\n\\nREADME badges for build status, version support, release tracking, and unittest coverage: https://import-balance.org/docs/docs/overview/\\n\\n`poststratify()` now supports `na_action` to either drop missing rows or treat missing values as their own category; **breaking change:** missing values default to a `\\"__NaN__\\"` category, so legacy drop behavior requires `na_action=\\"drop\\"`.\\n\\n```python\\nimport pandas as pd\\nfrom balance.weighting_methods.poststratify import poststratify\\n\\nsample_df = pd.DataFrame({\\"gender\\": [\\"Female\\", None, \\"Male\\", \\"Female\\"]})\\ntarget_df = pd.DataFrame({\\"gender\\": [\\"Female\\", None, None, \\"Male\\"]})\\n\\npoststratify(\\n    sample_df=sample_df,\\n    sample_weights=pd.Series([1, 1, 1, 1]),\\n    target_df=target_df,\\n    target_weights=pd.Series([1, 1, 1, 1]),\\n    variables=[\\"gender\\"],\\n    na_action=\\"add_indicator\\",\\n)[\\"weight\\"].tolist()\\n```\\n\\n```text\\n[0.5, 2.0, 1.0, 0.5]\\n```\\n\\n`model_matrix(add_na=False)` now actually drops rows with missing values while preserving categorical levels (matching the documented behavior, not just warning):\\n\\n```python\\nimport pandas as pd\\nfrom balance.utils.model_matrix import model_matrix\\n\\ndf = pd.DataFrame({\\"age\\": [20, None, 30], \\"group\\": [\\"A\\", \\"B\\", \\"A\\"]})\\nmodel_matrix(df, add_na=False)[\\"sample\\"]\\n```\\n\\n```text\\n    age  group[A]  group[B]\\n0  20.0       1.0       0.0\\n2  30.0       1.0       0.0\\n```\\n\\nUnder the hood, developers get: trimming parity for `rake()`/`poststratify()` via `trim_weights(..., target_sum_weights=...)`, warnings for very large targets (>=100k and >=10\xd7 sample), more consistent percentile trimming via explicit clipping, formula-driven summaries in `descriptive_stats(formula=...)`, consolidated diagnostics helpers (and **breaking change**: IPW `Sample.diagnostics()` output shape now always includes iteration/intercept summaries plus hyperparameters), and a split of the old `balance.util` into focused `balance.utils` submodules. Testing/typing updates include **100% coverage(!)**, migrating 32 files to `# pyre-strict`, modernized PEP 604 type hints, `TypedDict` definitions for plotting, renaming `Balance_*` classes to **BalanceDF** variants, adding Pyre checking in GitHub Actions via `.pyre_configuration.external`, and aligning formatting/CI tooling with Black 25.1.0. The raking algorithm was refactored to remove the `ipfn` dependency in favor of a vectorized NumPy implementation.\\n\\nBug fixes (v0.13\u2013v0.15) include: stable CBPS probability computation to avoid overflow, honoring `weighted=False` for target data in categorical QQ plots, earlier validation errors for null weights in `Sample.from_frame`, and `trim_weights()` now returning a consistent `float64` Series while preserving index ordering.\\n\\n**Breaking changes to watch when upgrading:** `poststratify()` defaults to `\\"__NaN__\\"` missing-category handling (use `na_action=\\"drop\\"` to drop), `model_matrix(add_na=False)` drops missing-data rows, percentile trimming uses explicit clipping bounds (thresholds may shift by ~1 observation), and IPW `Sample.diagnostics()` output shape changed to always include iteration/intercept summaries and hyperparameter settings.\\n\\nDetails are in: https://import-balance.org/docs/docs/changelog/\\n\\n## Community & Contributors\\n\\nA huge thank you to everyone who contributed to versions 0.13\u20130.15, including **@neuralsorcerer**, **@talgalili**, **@wesleytlee**, the BPG team in Tel-Aviv, and the broader community!\\n\\nWant to contribute? Check out our [contributing guide](https://github.com/facebookresearch/balance/blob/main/CONTRIBUTING.md).\\n\\n\\n## Get Started with v0.15.0\\n\\nUpgrade today:\\n\\n    python -m pip install -U balance\\n\\nResources:\\n- **Website:** https://import-balance.org/\\n- **GitHub:** https://github.com/facebookresearch/balance\\n- **Documentation:** https://import-balance.org/docs/docs/general_framework/\\n- **Tutorials:** https://import-balance.org/docs/tutorials/\\n- **Blog:** https://import-balance.org/blog/\\n- **Paper:** [balance \u2013 a Python package for balancing biased data samples](https://arxiv.org/abs/2307.06024)\\n\\nNeed help?\\n- **Ask questions:** https://github.com/facebookresearch/balance/issues/new?template=support_question.md\\n- **Report bugs:** https://github.com/facebookresearch/balance/issues/new?template=bug_report.md\\n- **Request features:** https://github.com/facebookresearch/balance/issues/new?template=feature_request.md"},{"id":"/2025/10/25/balance-0-12-0","metadata":{"permalink":"/blog/2025/10/25/balance-0-12-0","source":"@site/blog/2025/10/25/balance-0-12-0.md","title":"Balance in motion - v0.12.0 expands Python version support, visualizations, and statistical methods","description":"tl;dr \u2013 balance v0.12.0","date":"2025-10-25T00:00:00.000Z","formattedDate":"October 25, 2025","tags":[{"label":"python","permalink":"/blog/tags/python"},{"label":"open-source","permalink":"/blog/tags/open-source"},{"label":"survey-statistics","permalink":"/blog/tags/survey-statistics"},{"label":"package-update","permalink":"/blog/tags/package-update"}],"readingTime":3.85,"hasTruncateMarker":true,"authors":[{"name":"Tal Galili","title":"Machine Learning Engineer","url":"https://www.linkedin.com/in/tal-galili-5993085/"},{"name":"Wesley Lee","title":"Research Scientist","url":"https://www.linkedin.com/in/wesley-lee/"}],"frontMatter":{"title":"Balance in motion - v0.12.0 expands Python version support, visualizations, and statistical methods","authors":[{"name":"Tal Galili","title":"Machine Learning Engineer","url":"https://www.linkedin.com/in/tal-galili-5993085/"},{"name":"Wesley Lee","title":"Research Scientist","url":"https://www.linkedin.com/in/wesley-lee/"}],"tags":["python","open-source","survey-statistics","package-update"],"hide_table_of_contents":true},"prevItem":{"title":"Balance v0.15.0 - more sklearn models, diagnostics, and stability (100% test-coverage!)","permalink":"/blog/2026/01/20/balance-0-15-0"},"nextItem":{"title":"Bringing \\"balance\\" to your data","permalink":"/blog/2023/01/09/bringing-balance-to-your-data"}},"content":"**tl;dr \u2013 balance v0.12.0**\\n\\nWe\'re excited to announce [**balance v0.12.0**](https://pypi.org/project/balance/)! Since our initial release, [balance](https://import-balance.org/) has evolved into a comprehensive Python package for [adjusting biased samples](https://import-balance.org/blog/2023/01/09/bringing-balance-to-your-data/). This post highlights the most significant improvements from [v0.1.0 (2022-11-20)](https://github.com/facebookresearch/balance/releases/tag/0.1.0) through [v0.12.0 (2025-10-14)](https://github.com/facebookresearch/balance/releases/tag/0.12.0), showcasing how we\'ve made balance easier to use:\\n\\n- **Expanded compatibility:** Now supports Python 3.9\u20133.14 on Windows, macOS, and Linux, with smarter dependency management and a switch to the MIT license.\\n- **Major upgrades:** Improved statistical methods (IPW, raking, poststratification), interactive Plotly visualizations, and new variance/confidence interval tools.\\n- **Better experience:** Enhanced CLI, bug fixes, and expanded docs/tutorials for easier use and learning.\\n\\n[![balance_logo_horizontal](https://raw.githubusercontent.com/facebookresearch/balance/main/website/static/img/balance_logo/PNG/Horizontal/balance_Logo_Horizontal_FullColor_RGB.png)](https://import-balance.org/)\\n\\n\x3c!--truncate--\x3e\\n\\n\\n## Cutting-Edge Python Compatibility\\n\\n**balance** now supports all three major OS platforms: **Windows**, **macOS**, and **Linux** - for **Python 3.9 through 3.14**, ensuring you can use the latest Python features without compatibility concerns.\\n\\n### What\'s New:\\n- **Full support for Windows**\\n- **Full support for Python 3.11, 3.12, 3.13 and 3.14**\\n- **Smart dependency management** with version-specific constraints for `numpy`, `pandas`, `scipy`, and `scikit-learn` for Python 3.9-3.11.\\n- **Greater flexibility** for Python 3.12+ users with removed upper version constraints, while eliminating **260+ pandas deprecation warnings** and modernized our code.\\n- **Python 3.8 deprecated** due to typing incompatibilities\\n- **License Update** from GPL v2 to the **[MIT license](https://github.com/facebookresearch/balance/blob/main/LICENSE)** for greater flexibility and easier integration into your projects\\n\\n\\n## Methodological Improvements\\n\\n### Transition to scikit-learn for IPW\\n\\nWe\'ve migrated from `glmnet` to **scikit-learn\'s logistic regression** (v0.10.0) for our [inverse propensity weighting (IPW)](https://import-balance.org/docs/docs/statistical_methods/ipw/) method, bringing significant benefits:\\n\\n**Pros:**\\n- Windows OS support\\n- Python 3.11+ compatibility\\n- Eliminated `glmnet` dependency\\n\\n**Trade-offs:**\\n- Uses L2 penalties instead of L1 (slight weight differences)\\n- 2-5x slower than previous version\\n\\n### Raking Algorithm: Faster and More Reliable\\n\\nWe\'ve completely refactored our [raking (rake weighting)](https://import-balance.org/docs/docs/statistical_methods/rake/) implementation with an **array-based IPFN algorithm** that delivers:\\n\\n- **Support for marginal distribution target distributions** with the new `prepare_marginal_dist_for_raking` helper function\\n- **Better performance** across all Python versions\\n- **Consistent results** through automatic variable alphabetization\\n\\n\\n### Flexibility with Poststratification\\n\\nThe [poststratify](https://import-balance.org/docs/docs/statistical_methods/poststratify/) method now includes a **`strict_matching` parameter** (default `True`). When set to `False`, it gracefully handles missing sample cells by issuing warnings and assigning zero weights.\\n\\n\\n## Visualization and Summarization Enhancements\\n\\n### Interactive Plotting\\n\\nAll visualization functions now produce **interactive Plotly plots** by default:\\n\\n- **Customizable layouts** via `kwargs` (control width, height, and more)\\n- **New `plotly_plot_density`** for interactive kernel density estimation with support for \'kde\' plots in `plotly_plot_dist` and `plot_dist`\\n- **`BalanceWeightsDF.plot`** now uses Plotly instead of static seaborn plots\\n\\n![](https://import-balance.org/assets/images/fig_09_seaborn_outcome_kde_after-26fa9668164349253b2614335961ade9.png)\\n\\nAll bar plots now support **`ylim` argument** for precise y-axis control:\\n    s3_null.covars().plot(ylim=(0, 1))\\n\\n### Statistical Summaries\\n\\nNew variance and confidence interval methods make it easier to assess uncertainty:\\n\\n- `.var_of_mean()` - Variance of weighted means\\n- `.ci_of_mean()` - Confidence intervals for weighted means\\n- `.mean_with_ci()` - Combined mean with confidence intervals\\n- Enhanced `.summary()` method for `BalanceWeightsDF`\\n\\n## Developer Experience\\n\\n\\n### Notable Bug Fixes\\n\\n- Fixed `rm_mutual_nas` to preserve Series index\\n- Improved `Sample.from_frame` weight column detection (now recognizes \\"weights\\" and \\"weight\\")\\n- Better handling of int8/int16 columns (converts to float16)\\n- Fixed color assignments in comparison plots\\n- Resolved various edge cases in `plot_hist_kde` and `plot_bar`\\n\\n### CLI Improvements\\n\\nThe command-line interface now offers more control:\\n\\n- **Formula specification** via string arguments\\n- **Type standardization** controls\\n- **Original dtype preservation** with `--return_df_with_original_dtypes`\\n- **Flexible trimming** with `weight_trimming_mean_ratio=None` option\\n- **Enhanced logging** with dtype change warnings\\n\\n\\n## Documentation & Tutorials\\n\\nWe\'ve significantly expanded our [documentation](https://import-balance.org/docs/docs/general_framework/) with new tutorials:\\n- **[Quickstart](https://import-balance.org/docs/tutorials/quickstart/)** - Get started with balance basics\\n- **[Quickstart with Raking](https://import-balance.org/docs/tutorials/quickstart_rake/)** - Compare raking vs. IPW\\n- **[Quickstart with CBPS](https://import-balance.org/docs/tutorials/quickstart_cbps/)** - Covariate Balancing Propensity Score method\\n- **[Transformations and Formulas](https://import-balance.org/docs/tutorials/balance_transformations_and_formulas/)** - Advanced covariate preprocessing\\n- **[CBPS: R vs. Python Comparison](https://import-balance.org/docs/tutorials/comparing_cbps_in_r_vs_python_using_sim_data/)** - Validation against R\'s CBPS package\\n\\nAlso added a Link to [conference presentations](https://github.com/facebookresearch/balance/blob/main/website/static/docs/Balancing_biased_data_samples_with_the_balance_Python_package_-_ISA_conference_2023-06-01.pdf) (ISA 2023).\\n\\nThis extends our existing Statistical Methods Documentation:\\n- [Inverse Propensity Weighting (IPW)](https://import-balance.org/docs/docs/statistical_methods/ipw/)\\n- [Covariate Balancing Propensity Score (CBPS)](https://import-balance.org/docs/docs/statistical_methods/cbps/)\\n- [Post-stratification](https://import-balance.org/docs/docs/statistical_methods/poststratify/)\\n- [Raking](https://import-balance.org/docs/docs/statistical_methods/rake/)\\n\\n\\n## Community & Contributors\\n\\nA huge thank you to our contributors: **@talgalili**, **@wesleytlee**, **@SarigT**, **@ahakso**, **@stevemandala**, **@tomwagstaff-opml**, **@zbraiterman**, and **@luca-martial**!\\n\\nWant to contribute? Check out our [contributing guide](https://github.com/facebookresearch/balance/blob/main/CONTRIBUTING.md).\\n\\n---\\n\\n## Get Started Today\\n\\nReady to try **balance** or upgrade to v0.12.0?\\n\\n### Installation:\\n\\n    python -m pip install balance\\n\\n### Resources:\\n- **Website:** https://import-balance.org/\\n- **GitHub:** https://github.com/facebookresearch/balance\\n- **Documentation:** https://import-balance.org/docs/docs/general_framework/\\n- **Tutorials:** https://import-balance.org/docs/tutorials/\\n- **Blog:** https://import-balance.org/blog/\\n- **Paper:** [balance \u2013 a Python package for balancing biased data samples](https://arxiv.org/abs/2307.06024) (Sarig, Galili, & Eilat, 2023)\\n\\n### Get Help:\\n- **Ask questions:** https://github.com/facebookresearch/balance/issues/new?template=support_question.md\\n- **Report bugs:** https://github.com/facebookresearch/balance/issues/new?template=bug_report.md\\n- **Request features:** https://github.com/facebookresearch/balance/issues/new?template=feature_request.md\\n\\nWe welcome your feedback, questions, and contributions as we continue making **balance** the go-to tool for survey statistics and bias adjustment in Python!"},{"id":"/2023/01/09/bringing-balance-to-your-data","metadata":{"permalink":"/blog/2023/01/09/bringing-balance-to-your-data","source":"@site/blog/2023/01/09/bringing-balance-to-your-data.md","title":"Bringing \\"balance\\" to your data","description":"In research and data science, we sometimes encounter biased data: that is, data that has not been sampled completely randomly and suffers from an over- or under-indexing toward the population of interest. Survey data is an example in this regard. Surveys play an important role in providing measurements on subjective user experience indicators, such as sentiment and opinions, which cannot be measured by other means. But because survey data is collected from a self-selected group of participants, it needs to be analyzed carefully.","date":"2023-01-09T00:00:00.000Z","formattedDate":"January 9, 2023","tags":[],"readingTime":4.3,"hasTruncateMarker":true,"authors":[{"name":"Roee Eilat","title":"Research Scientist Manager @ Meta","url":"https://research.facebook.com/people/eilat-roee/"}],"frontMatter":{"title":"Bringing \\"balance\\" to your data","authors":[{"name":"Roee Eilat","title":"Research Scientist Manager @ Meta","url":"https://research.facebook.com/people/eilat-roee/"}],"tags":[],"hide_table_of_contents":true},"prevItem":{"title":"Balance in motion - v0.12.0 expands Python version support, visualizations, and statistical methods","permalink":"/blog/2025/10/25/balance-0-12-0"}},"content":"In research and data science, we sometimes encounter biased data: that is, data that has not been sampled completely randomly and suffers from an over- or under-indexing toward the population of interest. Survey data is an example in this regard. Surveys play an important role in providing measurements on subjective user experience indicators, such as sentiment and opinions, which cannot be measured by other means. But because survey data is collected from a self-selected group of participants, it needs to be analyzed carefully.\\n\\n\x3c!--truncate--\x3e\\n\\nBias in survey data is often the result of survey non-response or when the data collection suffers from [sampling bias](https://en.wikipedia.org/wiki/Sampling_bias). A similar issue arises in[ observational studies](https://en.wikipedia.org/wiki/Observational_study) when comparing treatment groups, and in any data that suffers from [selection bias](https://en.wikipedia.org/wiki/Selection_bias). Directly inferring insights from data with such biases or training ML models on such data can result in erroneous estimates or underperforming models. Hence, it is important for practitioners to understand if and how data is biased and, when possible, use statistical methods to minimize such biases.\\n\\nFor example, say we invite a random set of adults from a population of interest to participate in a survey we are running to estimate the sentiment towards some brand. If, for example, younger people have a higher propensity to participate in our survey, the proportion of younger people from the survey respondents will be higher than their proportion in the population. If younger people also have stronger affiliation with the brand, a simple average of the survey responses will be a biased estimate of the average sentiment in the population.\\n\\n\\nThe field of [survey statistics](https://en.wikipedia.org/wiki/Survey_methodology) offers methods for mitigating bias in samples, at least partially, by relying on auxiliary information (a.k.a., \u201ccovariates\u201d or \u201cfeatures\u201d). When such information is available for all items in the sample as well as for the population from which it was sampled, it can be used to create weights. Applying the weights to the data allows us to produce less biased estimates or models. In the example above, we may wish to adjust for non-response using not only age but other demographic information such as gender, education, etc. This can be done by weighting the sample to the population using the auxiliary information.\\n\\nThe figure below shows a sample (red) vs. population (blue) distribution representing the age bias described in the brand sentiment estimation example above. This figure was produced on simulated data which we set to be biased on other variables such as gender, education as well.\\n\\n![sample_vs_target_bar_chart](./sample_vs_target_bar_chart.webp)\\n\\nWhen weights are calculated and applied the weighted sample distribution (green) becomes much closer to the population distribution, and the weighted average will also be less biased to the extent the response is correlated with respondent\u2019s age. Notice the weighted distribution is not fully corrected, mainly because of bias-variance considerations.\\n\\n##  balance: a Python package for adjusting biased samples\\n\\nWith survey data playing a key role in research and product work at Meta, we observed a growing need for software tools that make survey statistics methods accessible for researchers and engineers. This has led us to develop \u201c_balance\u201d_: A Python package for adjusting biased data samples. In _balance_ we introduce a simple easy-to-use framework for weighting data and evaluating its biases with and without adjustments. The package is designed to provide best practices for weights fitting and offers several modeling approaches. The methodology in \u201cbalance\u201d already  supports ongoing automated survey data processing at Meta, as well as ad-hoc analyses of survey data by dozens of researchers every month.\\n\\nThe main workflow API of _balance_ includes three steps: (1) **understanding** the initial bias in the data relative to a target we would like to infer, (2) **adjusting** the data to correct for the bias by producing weights for each unit in the sample based on propensity scores, and (3) **evaluating** the final bias and the variance inflation after applying the fitted weights. The adjustment step provides several alternatives for the researcher to choose from. Current options include: Inverse propensity weighting of the form of logistic regression model based on LASSO (Least Absolute Shrinkage and Selection Operator [1]), Covariate Balancing Propensity Scores [2], and post-stratification. The focus is on providing a simple to use API, based on Pandas DataFrame structure, that can be used by researchers from a wide spectrum of fields.\\n\\n**We\u2019re releasing \u201c_balance_\u201d as a Meta Open Source project.** We want researchers, data scientists, engineers, and other practitioners to be able to apply these practices when they work in Python, benefiting from Meta\u2019s long research and experience in the field. With relation to \u201c_balance_\u201d we hope to also create an active community of data science practitioners where people can come together to discuss methodology and build tools that benefit survey-based research across academia and industry. If you work in Python with potentially biased data, we encourage you to use \u201cbalance\u201d in your project.\\n\\n\u201c_balance_\u201c website: [https://import-balance.org/](https://import-balance.org/)\\n\\ngithub repository: [https://github.com/facebookresearch/balance](https://github.com/facebookresearch/balance)\\n\\n**References**\\n\\n[1] Tibshirani, R. (1996). Regression shrinkage and selection via the lasso. Journal of the Royal Statistical Society: Series B (Methodological), 58(1), 267-288.\\n\\n[2] Imai, K., & Ratkovic, M. (2014). Covariate balancing propensity score. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 76(1), 243-263."}]}')}}]);